import streamlit as st

import os

import subprocess

import glob

import time

from openai import OpenAI

import google.generativai as genai



# --- 1. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ ---



def process_audio_and_summarize(api_keys, audio_file_path, results_container):

Â  Â  """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ ì „ì²´ ìš”ì•½ ê³¼ì •ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ì»¨í…Œì´ë„ˆì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""

Â  Â  openai_key, google_key = api_keys

Â  Â  summary = ""

Â  Â  temp_folder = f"temp_chunks_{int(time.time())}"



Â  Â  with st.spinner("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

Â  Â  Â  Â  Â  Â  client = OpenAI(api_key=openai_key)

Â  Â  Â  Â  Â  Â  genai.configure(api_key=google_key)

Â  Â  Â  Â  Â  Â  model = genai.GenerativeModel('gemini-1.5-flash')



Â  Â  Â  Â  Â  Â  # ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í• 

Â  Â  Â  Â  Â  Â  chunk_files = split_audio_with_ffmpeg(audio_file_path, temp_folder)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if chunk_files:

Â  Â  Â  Â  Â  Â  Â  Â  # í…ìŠ¤íŠ¸ ë³€í™˜ ë° ì§„í–‰ ìƒí™© í‘œì‹œ

Â  Â  Â  Â  Â  Â  Â  Â  progress_bar = results_container.progress(0, text="ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")

Â  Â  Â  Â  Â  Â  Â  Â  full_transcript = transcribe_audio_chunks(client, chunk_files, progress_bar)

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if full_transcript:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Geminië¡œ ìš”ì•½

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results_container.progress(1.0, text="í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ! Geminië¡œ ìš”ì•½ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prompt = f"ë‹¤ìŒ íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ì•„ë˜ í˜•ì‹ì— ë§ì¶° Markdown ì–‘ì‹ìœ¼ë¡œ ë©‹ì§€ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n[íšŒì˜ë¡ í…ìŠ¤íŠ¸]\n{full_transcript}\n\n[ìš”ì•½ í˜•ì‹]\n### ğŸ“Œ í•µì‹¬ ìš”ì•½\n\n### ğŸ“ ìƒì„¸ ë‚´ìš©\n- \n\n### ğŸš€ Action Items\n- "

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response = model.generate_content(prompt)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary = response.text



Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  results_container.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

Â  Â  Â  Â  finally:

Â  Â  Â  Â  Â  Â  # ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬

Â  Â  Â  Â  Â  Â  cleanup_temp_folder(temp_folder)

Â  Â  Â  Â  Â  Â  if os.path.exists(audio_file_path):

Â  Â  Â  Â  Â  Â  Â  Â  os.remove(audio_file_path)

Â  Â Â 

Â  Â  # ìµœì¢… ê²°ê³¼ í‘œì‹œ

Â  Â  if summary:

Â  Â  Â  Â  results_container.success("âœ… ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

Â  Â  Â  Â  results_container.markdown("---")

Â  Â  Â  Â  results_container.markdown(summary)

Â  Â  Â  Â  st.balloons()

Â  Â  else:

Â  Â  Â  Â  results_container.error("ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")



def split_audio_with_ffmpeg(file_path, temp_folder, chunk_duration_sec=1500):

Â  Â  """ffmpegì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ìë¥´ëŠ” í•¨ìˆ˜"""

Â  Â  if not os.path.exists(temp_folder): os.makedirs(temp_folder)

Â  Â  try:

Â  Â  Â  Â  command = f'ffmpeg -i "{file_path}" -f segment -segment_time {chunk_duration_sec} -c copy "{os.path.join(temp_folder, "chunk_%03d.m4a")}"'

Â  Â  Â  Â  subprocess.run(command, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

Â  Â  Â  Â  return sorted(glob.glob(os.path.join(temp_folder, "chunk_*.m4a")))

Â  Â  except Exception as e:

Â  Â  Â  Â  st.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")

Â  Â  Â  Â  return None



def transcribe_audio_chunks(client, chunk_files, progress_bar):

Â  Â  """ì˜¤ë””ì˜¤ ì¡°ê°ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""

Â  Â  full_transcript = ""

Â  Â  total_chunks = len(chunk_files)

Â  Â  for i, chunk_file in enumerate(chunk_files):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  with open(chunk_file, "rb") as audio_file:

Â  Â  Â  Â  Â  Â  Â  Â  transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="text")

Â  Â  Â  Â  Â  Â  full_transcript += transcript + " "

Â  Â  Â  Â  Â  Â  progress_bar.progress((i + 1) / total_chunks, text=f"í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘... ({i+1}/{total_chunks})")

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  st.error(f"'{os.path.basename(chunk_file)}' ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")

Â  Â  return full_transcript



def cleanup_temp_folder(folder):

Â  Â  """ì„ì‹œ í´ë”ì™€ ê·¸ ì•ˆì˜ íŒŒì¼ë“¤ì„ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜"""

Â  Â  if os.path.exists(folder):

Â  Â  Â  Â  for file in os.listdir(folder): os.remove(os.path.join(folder, file))

Â  Â  Â  Â  os.rmdir(folder)



# --- 2. Streamlit UI êµ¬ì„± ---



st.set_page_config(page_title="AI íšŒì˜ë¡ ìš”ì•½", page_icon="ğŸ™ï¸", layout="wide")

st.title("ğŸ™ï¸ AI íšŒì˜ë¡ ìš”ì•½ ì›¹ì•±")



# ì‚¬ì´ë“œë°”ì— API í‚¤ ì…ë ¥ë€

with st.sidebar:

Â  Â  st.header("API í‚¤ ì„¤ì •")

Â  Â  openai_api_key = st.text_input("OpenAI API í‚¤", type="password", placeholder="sk-...")

Â  Â  google_api_key = st.text_input("Google AI API í‚¤", type="password", placeholder="AIza...")

Â  Â  st.info("API í‚¤ëŠ” ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì‚¬ë¼ì§€ë©°, ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")



# ë©”ì¸ í™”ë©´ì— íŒŒì¼ ì—…ë¡œë”

st.subheader("ì´ë¯¸ ë…¹ìŒëœ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ (MP3, M4A, WAV...)", type=['mp3', 'm4a', 'wav', 'mp4'], key="uploader")



# íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œì˜ ë¡œì§

if uploaded_file:

Â  Â  if st.button("ìš”ì•½ ì‹œì‘í•˜ê¸°", key="upload_button"):

Â  Â  Â  Â  if not openai_api_key or not google_api_key:

Â  Â  Â  Â  Â  Â  st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„œë²„ì— ì„ì‹œë¡œ ì €ì¥

Â  Â  Â  Â  Â  Â  with open(uploaded_file.name, "wb") as f:

Â  Â  Â  Â  Â  Â  Â  Â  f.write(uploaded_file.getbuffer())

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # ê²°ê³¼ë¥¼ í‘œì‹œí•  ë™ì  ì»¨í…Œì´ë„ˆ ìƒì„±

Â  Â  Â  Â  Â  Â  results_container = st.container()

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ í˜¸ì¶œ

Â  Â  Â  Â  Â  Â  process_audio_and_summarize((openai_api_key, google_api_key), uploaded_file.name, results_container)


import streamlit as st
import os
import subprocess
import glob
import time
from openai import OpenAI
import google.generativai as genai

# --- 1. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ ---

def process_audio_and_summarize(api_keys, audio_file_path, results_container):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ ì „ì²´ ìš”ì•½ ê³¼ì •ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ì»¨í…Œì´ë„ˆì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    openai_key, google_key = api_keys
    summary = ""
    temp_folder = f"temp_chunks_{int(time.time())}"

    with st.spinner("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
        try:
            # AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = OpenAI(api_key=openai_key)
            genai.configure(api_key=google_key)
            model = genai.GenerativeModel('gemini-1.5-flash')

            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í• 
            chunk_files = split_audio_with_ffmpeg(audio_file_path, temp_folder)
            
            if chunk_files:
                # í…ìŠ¤íŠ¸ ë³€í™˜ ë° ì§„í–‰ ìƒí™© í‘œì‹œ
                progress_bar = results_container.progress(0, text="ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
                full_transcript = transcribe_audio_chunks(client, chunk_files, progress_bar)
                
                if full_transcript:
                    # Geminië¡œ ìš”ì•½
                    results_container.progress(1.0, text="í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ! Geminië¡œ ìš”ì•½ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    prompt = f"ë‹¤ìŒ íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ì•„ë˜ í˜•ì‹ì— ë§ì¶° Markdown ì–‘ì‹ìœ¼ë¡œ ë©‹ì§€ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n[íšŒì˜ë¡ í…ìŠ¤íŠ¸]\n{full_transcript}\n\n[ìš”ì•½ í˜•ì‹]\n### ğŸ“Œ í•µì‹¬ ìš”ì•½\n\n### ğŸ“ ìƒì„¸ ë‚´ìš©\n- \n\n### ğŸš€ Action Items\n- "
                    response = model.generate_content(prompt)
                    summary = response.text

        except Exception as e:
            results_container.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            # ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬
            cleanup_temp_folder(temp_folder)
            if os.path.exists(audio_file_path):
                os.remove(audio_file_path)
    
    # ìµœì¢… ê²°ê³¼ í‘œì‹œ
    if summary:
        results_container.success("âœ… ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        results_container.markdown("---")
        results_container.markdown(summary)
        st.balloons()
    else:
        results_container.error("ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

def split_audio_with_ffmpeg(file_path, temp_folder, chunk_duration_sec=1500):
    """ffmpegì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ìë¥´ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(temp_folder): os.makedirs(temp_folder)
    try:
        command = f'ffmpeg -i "{file_path}" -f segment -segment_time {chunk_duration_sec} -c copy "{os.path.join(temp_folder, "chunk_%03d.m4a")}"'
        subprocess.run(command, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return sorted(glob.glob(os.path.join(temp_folder, "chunk_*.m4a")))
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def transcribe_audio_chunks(client, chunk_files, progress_bar):
    """ì˜¤ë””ì˜¤ ì¡°ê°ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    full_transcript = ""
    total_chunks = len(chunk_files)
    for i, chunk_file in enumerate(chunk_files):
        try:
            with open(chunk_file, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="text")
            full_transcript += transcript + " "
            progress_bar.progress((i + 1) / total_chunks, text=f"í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘... ({i+1}/{total_chunks})")
        except Exception as e:
            st.error(f"'{os.path.basename(chunk_file)}' ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
    return full_transcript

def cleanup_temp_folder(folder):
    """ì„ì‹œ í´ë”ì™€ ê·¸ ì•ˆì˜ íŒŒì¼ë“¤ì„ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜"""
    if os.path.exists(folder):
        for file in os.listdir(folder): os.remove(os.path.join(folder, file))
        os.rmdir(folder)

# --- 2. Streamlit UI êµ¬ì„± ---

st.set_page_config(page_title="AI íšŒì˜ë¡ ìš”ì•½", page_icon="ğŸ™ï¸", layout="wide")
st.title("ğŸ™ï¸ AI íšŒì˜ë¡ ìš”ì•½ ì›¹ì•±")

# ì‚¬ì´ë“œë°”ì— API í‚¤ ì…ë ¥ë€
with st.sidebar:
    st.header("API í‚¤ ì„¤ì •")
    openai_api_key = st.text_input("OpenAI API í‚¤", type="password", placeholder="sk-...")
    google_api_key = st.text_input("Google AI API í‚¤", type="password", placeholder="AIza...")
    st.info("API í‚¤ëŠ” ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì‚¬ë¼ì§€ë©°, ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ë©”ì¸ í™”ë©´ì— íŒŒì¼ ì—…ë¡œë”
st.subheader("ì´ë¯¸ ë…¹ìŒëœ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ (MP3, M4A, WAV...)", type=['mp3', 'm4a', 'wav', 'mp4'], key="uploader")

# íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œì˜ ë¡œì§
if uploaded_file:
    if st.button("ìš”ì•½ ì‹œì‘í•˜ê¸°", key="upload_button"):
        if not openai_api_key or not google_api_key:
            st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„œë²„ì— ì„ì‹œë¡œ ì €ì¥
            with open(uploaded_file.name, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # ê²°ê³¼ë¥¼ í‘œì‹œí•  ë™ì  ì»¨í…Œì´ë„ˆ ìƒì„±
            results_container = st.container()
            
            # í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ í˜¸ì¶œ
            process_audio_and_summarize((openai_api_key, google_api_key), uploaded_file.name, results_container)

